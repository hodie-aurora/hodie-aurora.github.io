---
layout:     post   				# 使用的布局（不需要改）
title:      Kubemate QA02            		# 标题 
subtitle:   Kubemate QA02				#副标题
date:       2025-06-03				# 时间
author:     zhaohaiwen 				# 作者
header-img: img/post-bg-2025-01-07.jpg		#这篇文章标题背景图片
catalog: true 					# 是否归档
tags:						#标签
    - Kubemate
---
**模块2：监控与告警**

**普通问题 (20)**

第一部分：Prometheus 和 Thanos

1. Prometheus 是如何部署的？采用了哪些高可用配置？
   我们的 Prometheus 采用双副本模式部署以实现高可用。每个 Prometheus 实例都配置了唯一的外部标签，通过标签将 Thanos 进行数据去重。这种架构确保了单个 Prometheus 实例故障不会导致监控数据采集中断。
   为了实现长期存储和全局查询，我们集成了 Thanos。每个 Prometheus Pod 内都运行一个 Thanos Sidecar 容器，它负责两件事：一是将 Prometheus 本地生成的 TSDB 数据块上传到 MinIO 对象存储；二是通过 gRPC 接口向 Thanos Querier 提供该实例内存中的实时数据。
   Thanos Querier 作为统一查询入口，会聚合所有 Sidecar 的实时数据和 Store Gateway 提供的历史数据。它根据外部标签对来自不同副本的数据进行合并去重，从而提供一个统一的全局数据视图。Thanos Store Gateway 组件的作用是连接 MinIO，使其存放的海量历史数据可以被查询。最后，Thanos Compactor 作为一个后台服务，负责对 MinIO 中的数据块进行压缩、降采样和管理数据生命周期，以此来优化存储成本和历史数据查询性能。
2. Thanos 的哪些组件被部署了（如 Sidecar, Querier, Store Gateway, Compactor）？它们各自的作用是什么？具体是如何部署的（不要提供代码）？
   我们部署了 Thanos 的四个核心组件：Sidecar、Querier、Store Gateway 和 Compactor。
   Thanos Sidecar 与 Prometheus 部署在同一个 Pod 中，作为一个伴生容器。这种部署方式使其可以直接访问 Prometheus 的数据卷。它的作用是上传历史数据块到 MinIO，并向 Querier 暴露一个 gRPC 接口以查询该 Prometheus 实例的实时数据。
   Thanos Querier 以无状态、可水平扩展的 Deployment 方式部署，并通过 Service 对外提供查询服务。它的作用是接收 PromQL 查询，然后将请求分发给所有的 Sidecar 和 Store Gateway，最后将返回的结果进行聚合与去重，形成最终的全局数据。
   Thanos Store Gateway 同样以无状态的 Deployment 部署，可以按需扩缩容。它的职责是扫描 MinIO 中的数据块元数据，并向 Querier 提供一个 gRPC 接口，使得对象存储中的历史数据能够被查询。
   Thanos Compactor 作为一个单例组件部署，通常是一个单副本的 Deployment。它的作用是在后台对 MinIO 中的数据进行优化，包括将小数据块合并成大块、对老数据进行降采样以提升长期查询效率，以及执行数据保留策略。
3. MinIO 是如何作为 Thanos 的长期存储的？存储桶的配置和生命周期管理是怎样的？
   minio使用thanos持久化Prometheus数据的工作流程大概是：

   连接配置：
   1：需要与minio交互的thanos组件都通过挂载configmap配置文件存储minio endpoint、访问密钥、私有密钥、存储桶等信息与minio进行通信

   2：数据上传与访问：Thanos Sidecar 会定期将 Prometheus 本地生成的 TSDB 数据块上传到这个指定的 MinIO 存储桶中。而 Thanos Store Gateway 则会监控这个存储桶，将其中数据块的元数据索引在内存中，以便 Thanos Querier 能够查询到这些历史数据。

   关于存储桶的配置和生命周期管理：

   存储桶配置：我们的thanos有专用的存储桶并且关闭了版本控制，因为thanos数据块是不可变的，关闭版本控制可以避免不必要的开销，这个存储桶仅允许thanos所在的命名空间进行读写操作

   生命周期管理：我们没有使用minio自身的生命周期管理策略来管理监控数据，我们通过Thanos Compactor 来执行数据保留，我们的保留策略是原始精度数据 30 天，5 分钟降采样数据 90 天，1 小时降采样数据 1 年，Compactor 根据这些规则自动删除minio中过期的符合条件的数据块

   这种方式将数据管理的逻辑保留在 Thanos 层，与底层存储解耦，逻辑更清晰，也更容易适配不同的对象存储后端。
4. Prometheus 的抓取配置 (scrape configs) 是如何管理的？是否支持动态更新？
5. 监控数据的查询性能如何？特别是在查询大范围时间序列数据时，Thanos 的降采样（down-sampling）是如何帮助提升性能的？
6. 你们是如何管理 Prometheus 指标的基数（Cardinality）问题的？有没有遇到过高基数带来的性能问题，又是如何解决的？
7. Thanos Querier 是如何对来自两个 Prometheus 副本的数据进行去重的？这个机制的原理是什么？
8. 你们为 Prometheus 和 Thanos 的各个组件设置了怎样的资源请求（requests）和限制（limits）？在资源规划上有什么考量？

第二部分：Prometheus 和 Alertmanager

1. Alertmanager 支持哪些告警渠道？邮件和短信告警是如何配置的？告警的原理是什么？
2. 平台预定义了哪些关键的告警规则？用户是否可以自定义告警规则？如果可以，是如何实现的？
3. 告警的抑制 (Silencing) 和去重 (Deduplication) 是如何通过 Alertmanager 实现的？请举例说明。
4. 告警通知中包含哪些关键信息，以帮助用户快速定位问题？模板是如何定制的？
5. 请描述一个告警从 Prometheus 触发到通过 Alertmanager 发送到用户手中的完整生命周期。
6. 你们如何处理告警风暴（Alert Storm）和告警抖动（Flapping）的问题？
7. Alertmanager 的路由（routing）规则是如何配置的？能否举一个例子，比如将不同严重程度或不同业务线的告警发送给不同的人？

第三部分：其他

1. 应用健康状态是如何定义的？通过哪些指标来衡量？
2. 用户如何通过仪表盘下钻 (drill down) 查看特定应用或组件的详细监控数据？
3. 是否监控 Kubernetes 控制平面组件（API Server, Scheduler, Controller Manager, etcd）的健康状况？主要关注哪些指标？
4. 应用性能指标（如 QPS, 延迟, 错误率）是如何采集和展示的？这部分是基于 OpenTelemetry 吗？
5. 监控系统本身的健康状况是如何监控的（"meta-monitoring"）？比如 Prometheus 自身是否健康，Thanos 组件是否正常工作。

**刁钻问题 (5)**

第一部分：Prometheus 和 Thanos

1. 当监控数据量巨大时，Thanos Compactor 和 Store Gateway 的性能瓶瓶颈可能出现在哪里？有哪些优化策略？
2. 如何处理 Prometheus 实例间的抓取目标冲突或重复抓取问题，尤其是在多集群联邦查询的场景下？
3. 在金融等对数据准确性要求极高的场景，Prometheus Pull 模式可能存在的微小数据延迟或因目标实例宕机导致的抓取失败（数据丢失），是否会构成问题？你们是如何缓解或应对这种风险的？

第二部分：Prometheus 和 Alertmanager

4. Alertmanager 的高可用集群是如何保证在网络分区（Network Partition）或节点故障情况下，告警状态（如 silences, notifications）的一致性，以及如何确保不丢失、不重复发送告警的？

第三部分：其他

5. 对于需要非常低延迟的告警（例如，几秒内必须响应的交易系统关键故障），当前的 Prometheus -> Alertmanager 架构能否满足？如果不能，有哪些改进方向或替代方案可以考虑？
