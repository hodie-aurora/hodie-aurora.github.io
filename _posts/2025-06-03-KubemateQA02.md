---
layout:     post   				# 使用的布局（不需要改）
title:      Kubemate QA02            		# 标题 
subtitle:   Kubemate QA02				#副标题
date:       2025-06-03				# 时间
author:     zhaohaiwen 				# 作者
header-img: img/post-bg-2025-01-07.jpg		#这篇文章标题背景图片
catalog: true 					# 是否归档
tags:						#标签
    - Kubemate
---
**模块2：监控与告警**

* **普通问题 (20)**
  1. Prometheus 是如何部署的？采用了哪些高可用配置？ 
  2. Thanos 的哪些组件被部署了（如 Sidecar, Querier, Store Gateway, Compactor）？它们各自的作用是什么？ 
  3. MinIO 是如何作为 Thanos 的长期存储的？存储桶的配置和生命周期管理是怎样的？
  4. Alertmanager 支持哪些告警渠道？邮件和短信告警是如何配置的？告警的原理是什么？
  5. 平台预定义了哪些关键的告警规则？用户是否可以自定义告警规则？
  6. Vue3 仪表盘上展示了哪些核心的集群健康指标？
  7. 应用健康状态是如何定义的？通过哪些指标来衡量？
  8. 资源使用率（CPU, 内存, 网络, 磁盘）是如何在仪表盘上展示的？
  9. 应用性能指标（如 QPS, 延迟, 错误率）是如何采集和展示的？
  10. Prometheus 的抓取配置 (scrape configs) 是如何管理的？是否支持动态更新？
  11. Thanos Querier 是如何实现跨集群指标查询的？
  12. 告警的抑制 (Silencing) 和去重 (Deduplication) 是如何通过 Alertmanager 实现的？ 
  13. 用户如何通过仪表盘下钻 (drill down) 查看特定应用或组件的详细监控数据？
  14. 是否监控 Kubernetes 控制平面组件（API Server, Scheduler, Controller Manager, etcd）的健康状况？
  15. 监控系统本身的健康状况是如何监控的（"meta-monitoring"）？
  16. Grafana 是否也作为仪表盘方案的一部分？如果是，它与 Vue3 仪表盘是如何分工的？
  17. 针对自定义应用，用户如何方便地接入 Kubemate 的监控体系？
  18. 告警通知中包含哪些关键信息，以帮助用户快速定位问题？
  19. 监控数据的查询性能如何？特别是在查询大范围时间序列数据时。
* **刁钻问题 (5)**
  1. 当监控数据量巨大时，Thanos Compactor 和 Store Gateway 的性能瓶颈可能出现在哪里？有哪些优化策略？ 
  2. 如何处理 Prometheus 实例间的抓取目标冲突或重复抓取问题，尤其是在多集群联邦查询的场景下？
  3. Alertmanager 的高可用集群是如何保证在网络分区或节点故障情况下，告警状态的一致性和不丢失、不重复发送告警的？ 
  4. 对于需要非常低延迟的告警（例如，交易系统中的关键故障），当前的监控架构能否满足？如果不能，有哪些改进方向？
  5. 在金融等对数据准确性要求极高的场景，Prometheus Pull 模式可能存在的微小数据延迟或不一致，是否会构成问题？如何缓解？