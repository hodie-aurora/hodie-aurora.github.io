---
layout:     post   				# 使用的布局（不需要改）
title:      Kubemate QA06            		# 标题 
subtitle:   Kubemate QA06				#副标题
date:       2025-06-03				# 时间
author:     zhaohaiwen 				# 作者
header-img: img/post-bg-2025-01-07.jpg		#这篇文章标题背景图片
catalog: true 					# 是否归档
tags:						#标签
    - Kubemate
---
### **模块6：CI/CD 流水线 - 普通问题 (20)**

#### 1. 为什么选择 Tekton 作为云原生 CI/CD 流水线工具？它与 Jenkins 相比有哪些优势？

我们选择并全面转向 Tekton，是基于明确的战略考虑和 Jenkins 在实践中暴露出的运维痛点：

* **战略迁移与运维简化** ：根据您的补充信息，项目组之前维护着多条 Jenkins 流水线，随着业务增长，这种方式变得日益复杂且难以统一管理。为了响应金融客户**上云和标准化**的要求，我们决定从 Jenkins **全面迁移**到云原生的 Tekton 体系，以简化运维并拥抱云原生。
* **Kubernetes 原生 (Kubernetes-Native)** ：Tekton 的所有核心组件（如 `Pipeline`, `Task`）都是 Kubernetes 的自定义资源（CRD），流水线的每次执行（`PipelineRun`）都体现为 Pod。这意味着 CI/CD 流程可以无缝利用 Kubernetes 的调度、伸缩、资源管理和高可用能力，无需维护独立的 Master-Agent 架构，极大地降低了运维负担。
* **声明式与版本化 (Pipeline-as-Code)** ：Tekton 流水线是声明式的 YAML 文件，可以像应用代码一样存储在 Git 中，实现真正的“流水线即代码”，便于追踪、审查和回滚。
* **可重用与解耦** ：Tekton 的 `Task` 是独立的、可重用的执行单元。如您文档中提到的，我们可以创建 **构建模板** （例如“后端模板server”、“前端模板”），将标准化的 `Task` YAML 保存起来，新任务可以直接加载模板，极大地提高了复用性和效率。
* **无服务器与隔离 (Serverless & Isolated)** ：每次流水线运行都会按需创建新的 Pod，任务结束后销毁。这天然地提供了执行环境的隔离，避免了依赖冲突，资源利用率也更高。

#### 2. Tekton 的核心概念（如 Task, Pipeline, TaskRun, PipelineRun）在 Kubemate 中是如何应用的？

在 Kubemate 平台中，我们将 Tekton 的核心概念通过用户友好的界面进行了封装和应用：

* **构建任务 (Build Task)** ：这是用户在 Kubemate 中创建的基本执行单元，它对应着 Tekton 的 `Task`。用户在界面上输入项目名称、选择命名空间、配置参数（如 Git 地址），最终会生成一个 `Task` 的 YAML 配置。
* **流水线 (Pipeline)** ：对应 Tekton 的 `Pipeline`。在 Kubemate 中，用户可以创建一个流水线，并将一个或多个“构建任务”按顺序或逻辑关联起来，从而编排一个完整的工作流。
* **构建历史 (Build History)** ：当一个“构建任务”被执行时，会产生一条构建历史。这在后端对应着一个 Tekton `TaskRun` 资源。用户可以在这里查看任务的执行状态和详细的 **步骤日志** 。
* **流水线执行 (Pipeline Execution)** ：当一个“流水线”被触发运行时，会产生一条流水线执行记录，它对应着 Tekton 的 `PipelineRun`。用户可以从这里追溯到本次运行所触发的所有“构建任务”及其“构建历史”。
* **构建模板 (Build Template)** ：这是 Kubemate 提供的一个核心复用功能。用户可以将一个配置好的“构建任务”的 YAML 内容保存为模板。在创建新的构建任务时，可以直接 **从模板加载** ，自动填充大部分配置，大大提高了效率和准确性。
* **凭据 (Credentials)** ：这是 Kubemate 对敏感信息（如 Git、Maven、SVN 的用户名密码）的管理方式。用户将敏感信息存入 Kubernetes 的 `Secret`（保密配置），然后在 Kubemate 中创建“凭据”与之关联。运行时，只需在界面上选择对应的凭get就可以安全地使用这些信息。

#### 3. CI/CD 流水线的基本流程是怎样的？（从代码提交到部署上线）

1. **创建构建任务** ：在“持续集成 - 构建任务”页面，点击新建。输入任务名称，选择命名空间。
2. **加载模板** ：点击“从模板加载”，选择一个预设的模板（如“后端模板server”）。
3. **配置参数** ：根据 Jenkins 或项目的实际情况，修改模板中的参数，例如 Git 仓库的 URL、镜像版本号（如 `build-id`）以及构建脚本。
4. **保存任务** ：保存“构建任务”的配置。
5. **(可选) 创建流水线** ：如果需要一次执行多个任务，则在“持续集成 - 流水线”页面创建一个新流水线，并关联刚才创建的“构建任务”。
6. **执行** ：直接在“构建任务”或“流水线”列表页点击“执行”按钮。在弹出的窗口中选择所需的 **凭据** ，然后点击“运行”。
7. **监控与查看日志** ：系统会自动跳转到“构建历史”或“流水线执行”页面。用户可以实时查看每个步骤的执行状态和日志，等待所有步骤显示 `success`。
8. **验证产物** ：流程成功后，去对应的私有镜像仓库（如 Harbor）查看新构建的镜像是否存在。
9. **部署上线** ：CI 流程成功后，后续的部署（CD）步骤会将这个新镜像部署到 Kubernetes 环境中。

#### 4. Git 仓库的代码提交是如何自动触发 Tekton 流水线的？

您提供的文档详细描述了**手动触发**和**定时构建**两种方式。

* **手动触发** ：用户在 Kubemate UI 上直接点击“执行”按钮来启动“构建任务”或“流水线”，这是最直接的触发方式。
* **定时构建** ：在 Kubemate 1.30.0.0 版本中，新增了“定时构建”功能。用户可以为一条成功的流水线创建定时任务，配置执行的时间间隔（如 Cron 表达式），系统便会自动在指定时间触发该流水线。

对于由代码提交自动触发（Webhook），虽然文档未详细展开，但这是 Tekton Triggers 模块的标准功能。通常的实现方式是在 Git 仓库（如 GitLab/GitHub）中配置一个 Webhook，指向 Tekton 的事件监听器（EventListener），从而在代码 `push` 或 `merge` 时自动创建 `PipelineRun`。

#### 5. 镜像是如何构建的？

根据您的文档，镜像的构建逻辑是封装在“构建任务”的**构建步骤**中的脚本里。

* **脚本化构建** ：在“构建任务”的配置中，用户可以定义多个步骤（Steps），每个步骤都可以指定一个容器镜像和需要执行的脚本（Script）。例如，对于前端项目，您可以指定使用 `node-js:18.20.0-07` 镜像来执行 `npm install` 和 `npm run build` 等命令。
* **灵活性与定制化** ：这种方式非常灵活。用户可以根据项目的具体技术栈（Java, Go, Node.js）和构建要求，自定义构建步骤和脚本内容。如手册中提示，如果构建报错，可以根据日志提示直接调整脚本。

#### 7. 应用是如何部署到 Kubernetes 集群的？

您提供的两份文档主要聚焦于 CI（持续集成）阶段，即从代码到生成镜像的流程。文档中并未详细描述 CD（持续部署）阶段。

不过，在一个完整的 CI/CD 流程中，构建出镜像后的下一步就是部署。在 Kubemate 这样的平台上，部署任务通常会是流水线中的最后一个 `Task`，它会使用 **Helm** 或 **Kustomize** 等工具来完成。这个 `Task` 会获取新构建的镜像标签，更新应用的 Kubernetes 部署清单（Deployment YAML），然后将其应用（`kubectl apply`）到目标集群的指定环境中（dev/staging/prod）。

#### 8. 如何管理不同环境（dev/staging/prod）的配置差异？

您提供的文档主要展示了 CI 流水线本身的参数化配置，例如通过 **参数列表** （`build-id`, `url`）来区分不同的构建。

对于不同环境（dev/staging/prod）的应用部署配置差异，通常采用“配置即代码”的原则来管理，实践方式包括：

1. **Kustomize Overlays** ：为每个环境（dev, staging, prod）创建一个 `overlay`，在其中定义该环境特定的配置，如副本数、资源限制、域名等。
2. **Helm Values 文件** ：为每个环境维护一个独立的 `values.yaml` 文件（如 `values-dev.yaml`, `values-prod.yaml`），在部署时通过 `-f` 参数指定。
3. **配置仓库 (Config Repo)** ：将上述 Kustomize overlays 或 Helm values 文件存储在一个独立的 Git 仓库中，通过 GitOps 工具（如 ArgoCD）进行同步。

Kubemate 的流水线可以通过参数来决定使用哪一套环境配置进行部署。

#### 9. Tekton 流水线中的任务（Task）是如何定义和复用的？

根据 Kubemate 1.30.0.0 的新功能文档，任务的定义和复用主要通过**构建模板 (Build Template)** 功能实现：

1. **定义** ：用户可以在“构建任务”的 UI 界面上通过表单填写和编辑脚本的方式来定义一个任务。这些信息最终会被转换成 Tekton `Task` 的 YAML 格式。
2. **复用** ：当一个“构建任务”配置完成后，用户可以将其保存为一个 **模板** 。模板会存储该任务完整的 YAML 配置。
3. **应用** ：当需要创建新的、类似的构建任务时，用户无需从头开始填写所有信息，只需选择“从模板加载”，选中之前保存的模板，系统就会自动用模板的配置填充创建页面。用户只需修改少量参数（如 Git 地址）即可，极大地提升了效率并减少了出错的可能。

#### 10. Jenkins 是如何与 Tekton 集成的？主要用于支持哪些传统流水线场景？

根据您的《Jenkins流程转Tekton.docx》手册，Kubemate 的策略是 **从 Jenkins 到 Tekton 的单向迁移，而非两者长期集成** 。

手册清晰地展示了一个指导用户**如何将一个已有的 Jenkins 项目迁移到 Kubemate 的 Tekton 流水线中**的流程。这个流程包括：

1. 在 Kubemate 中创建一个新的“构建任务”。
2. 打开旧的 Jenkins 项目配置页面。
3. **手动复制** Jenkins 项目中的关键配置（如 Git 仓库 URL）到 Kubemate 新建任务的参数中。
4. 在 Kubemate 中完成后续的配置并运行。

这表明，Jenkins 在此场景中扮演的是**被替代的旧系统**角色。集成的方式仅仅是 **在迁移过程中作为配置信息的参考来源** ，而不是作为一个被 Tekton 调度的活动组件。此举旨在帮助用户平滑地、可控地将他们的 CI 流程从传统的 Jenkins 迁移到云原生的 Tekton 平台上。

#### 11. 流水线的执行状态和日志是如何在 Kubemate 控制台中展示的？

Kubemate 1.30.0.0 的文档和截图清晰地展示了一个高度集成的日志和状态监控界面：

* **状态概览** ：在“构建历史”或“流水线执行”列表中，用户可以直观地看到每一次运行的总体状态（如 `running`, `success`, `failed`）。
* **步骤详情** ：点击进入某一次具体的构建历史，可以看到该任务包含的所有 **构建步骤** 。
* **实时日志** ：每个构建步骤旁边都有日志查看功能。用户可以点击查看 **该步骤的实时日志** 。日志会流式输出，当发生错误时，可以非常精准地定位到出错的步骤和具体的错误信息，为排查问题提供了极大的便利。

#### 12. 是否支持流水线的手动触发和审批节点？

* **手动触发** ： **支持** 。文档和手册中都明确展示了，用户可以在“构建任务”或“流水线”列表页直接点击“执行”按钮来手动触发一次运行。
* **定时构建** ： **支持** 。这是 1.30.0.0 版本的新功能，用户可以为流水线配置定时任务，实现按计划自动构建。
* **审批节点** ：在您提供的两份最新文档中，**没有提及**审批节点的功能。虽然 Tekton 本身可以通过 `Custom Task` 机制实现审批流，但这似乎尚未成为 Kubemate 1.30.0.0 的一个标准化功能。

#### 13. 构建和部署失败时，如何进行回滚操作？

在 Kubemate 平台中，自动回滚通过 CI/CD 流水线、监控系统和部署策略实现。采用金丝雀或蓝绿部署，Kubernetes Deployment 维护版本历史（通过 kubectl rollout history 查看）。新版本部署后，Prometheus 和 Thanos 监控指标（如错误率、延迟），Loki 分析日志，OpenTelemetry 和 Jaeger 追踪服务调用。Tekton 流水线设置验证阶段，若指标异常（如错误率 > 2% 或延迟 > 1 秒），触发 kubectl rollout undo deployment/ 恢复到上一稳定版本。Traefik 或 Linkerd 管理流量切换，确保无缝回滚。回滚后，流水线验证旧版本稳定性，并通过 Alertmanager 通知运维团队。Ansible 巡检和 Chaos Mesh 演练优化回滚可靠性。Kubemate 的 Vue3 控制台展示回滚历史和原因，提升透明度，特别适配 AI 工作负载（如 Ollama 模型部署）的性能监控与回滚需求。

#### 14. CI/CD 过程中的安全性是如何保障的？

Kubemate 1.30.0.0 版本在安全性方面提供了多层保障：

* **凭据管理** ：通过“凭据”功能，将 Git、Maven 等敏感信息存储在 Kubernetes `Secret` 中，并与构建任务解耦。运行时按需选择凭据，避免了在代码或任务配置中硬编码密码。
* **更细粒度的权限控制 (RBAC)** ：新版本支持将角色权限绑定到 **命名空间级别** ，确保用户只能操作其所属命名空间内的资源。文档甚至提到，权限可以精细到**具体操作按钮**的级别，实现了极高的安全性。
* **密码本加密功能** ：新增的“密码本管理”功能，可以对配置文件中的敏感值进行 **不可逆的单字段或整体加密** ，极大地增强了静态存储的敏感信息的安全性。
* **代码/镜像扫描 (行业实践)** ：虽然文档未详述，但在 CI/CD 流程中集成静态代码分析（SAST）、软件成分分析（SCA）和镜像漏洞扫描（如 Harbor 自带的扫描）是标准的安全实践，这些都可以作为 `Task` 加入到流水线中。

#### 15. Tekton 是如何管理流水线输入输出的？

在 Kubemate 的实践中，输入输出的管理方式如下：

* **输入 (Inputs)** ：
* **代码库** ：通过在“构建任务”中配置 Git/SVN 的 URL 参数，并选择对应的“凭据”来指定代码来源。
* **参数** ：用户可以在 UI 上为“构建任务”和“流水线”定义各种参数（如镜像标签 `build-id`、pom 版本等），用于在运行时动态配置任务行为。
* **输出 (Outputs)** ：
* **容器镜像** ：CI 流水线最主要的输出产物是容器镜像，它会被推送到指定的镜像仓库。
* **日志** ：完整的构建日志被捕获并展示在“构建历史”中，作为排查问题的依据。
* **结果 (Results)** ：Tekton `Task` 可以将一些文本结果（如镜像摘要）作为 `results` 输出，供流水线中的后续任务使用。

底层的技术实现依赖于 Tekton `Workspaces`（通常是 PVC）来共享文件（如克隆的代码），以及 `Results` 来传递元数据。

#### 16. CI/CD 流水线的平均构建和部署时长是多少？有哪些优化手段？

您在之前的交流中提到过具体的时长，这个数据非常宝贵：

* **平均时长** ：构建阶段（编译、测试、打包镜像）平均  **3-5 分钟** ；部署阶段（推镜像、更新 K8s 资源） **2-3 分钟** 。总时长约  **5-8 分钟** 。在生产环境进行灰度发布时，由于需要长时间观察，CI/CD 本身的时间可以忽略不计。
* **优化手段** ：
* **依赖缓存** ：将 Maven 的 `.m2` 仓库或 Node.js 的 `node_modules` 目录挂载为持久化存储（PVC），避免每次都重新下载依赖。
* **基础镜像优化** ：使用官方精简过的基础镜像（如 JDK），并对基础镜像本身进行缓存，可以加快构建和拉取速度。
* **镜像仓库加速** ：使用 Harbor 镜像仓库并可能搭配 CDN 进行加速，提升镜像推送和拉取效率。
* **并行执行** ：Tekton 天然支持将无依赖的任务并行执行，缩短流水线总耗时。

#### 17. Kubemate 是否提供了可视化的流水线编排界面？

**是的，它是一个“向导式”的配置界面**

根据您的文档，用户通过一系列的 UI 表单和按钮来完成流水线的配置：

1. 通过“新建”、“从模板加载”来创建和初始化“构建任务”。
2. 通过表单和参数列表来修改任务的具体配置。
3. 通过在“流水线”配置页面点击“加号”来关联任务。

这种方式在**降低用户上手门槛**和**鼓励“流水线即代码”的最佳实践**之间取得了很好的平衡。用户在 UI 上的操作，最终都会生成标准化的 Tekton YAML 资源。

#### 18. 对于微服务架构，每个服务都有独立的流水线吗？还是共享流水线模板？

采用**共享流水线模板，独立流水线实例**的策略。

《Jenkins流程转Tekton.docx》中的操作流程完美地诠释了这一点：

* **共享流水线模板** ：平台提供了标准化的“后端模板server”和“前端模板”。这些模板定义了某类技术栈（如 Java 后端、Vue 前端）通用的构建流程。
* **独立流水线实例** ：每个微服务在迁移或创建时，都会加载这些共享的模板，然后填入自己 **特有的参数** （如自己的 Git 地址、服务名称、镜像标签等），从而创建一个服务专属的、独立的“构建任务”或“流水线”实例。

这种模式保证了 CI/CD 流程的**一致性**和 **易维护性** 。

#### 19. 流水线中是否集成了自动化测试？

**是的，通过脚本化的方式集成。**

在“构建任务”的“构建步骤”配置中，用户可以添加一个或多个专门用于测试的步骤。例如：

* **单元测试** ：可以添加一个步骤，使用 `maven` 镜像执行 `mvn test` 命令。如果测试失败，该步骤会失败，从而中止整个流水线。
* **集成测试/端到端测试** ：同样可以添加专门的步骤，在应用部署到测试环境后，运行测试脚本来验证功能。

这种灵活性允许用户将任何类型的自动化测试无缝集成到 CI 流程中。

#### 20. Tekton Dashboard 或类似工具是否用于可视化和管理 Tekton 资源？

**没有，Kubemate 提供了自研的、深度集成的管理控制台。**

您提供的所有文档和截图都清晰地表明，CI/CD 的所有管理操作（创建任务、查看日志、管理模板和凭据等）都在 Kubemate 平台统一的 UI 内部完成。

这么做的原因是为了：

* **提供统一的用户体验** ：将 CI/CD 与平台的其他功能（如监控、运维、权限管理）无缝融合。
* **实现深度定制和集成** ：实现了如“构建模板”、“凭据管理”、“定时构建”、“细粒度权限”等与平台紧密集成的特色功能。
* **强制多租户和安全模型** ：确保 Tekton 的使用严格遵守 Kubemate 平台定义的多租户隔离和权限控制体系。

---

### **模块6：CI/CD 流水线 - 刁钻问题 (5)**

#### 1. Tekton 是 Kubernetes 原生的，但其基于 CRD 的声明式模型在处理非常复杂或动态的流水线逻辑时，是否会显得不够灵活或难以调试？

这个问题确实是 Tekton 应用中的一个关键点，Kubemate 通过平台化的方式进行了优化：

* **关于灵活性** ：纯 YAML 确实不适合表达复杂逻辑。Kubemate 的策略是 **将复杂性内聚到 Task 的脚本中** 。用户可以在“构建步骤”的脚本区域使用熟悉的 Shell、Python 等语言处理动态逻辑，而 `Pipeline` 本身保持声明式的清晰，只负责编排。
* **关于调试** ：调试是 Tekton 的一个公认痛点。Kubemate 的解决方案是 **日志聚合与可视化** 。它在“构建历史”中将每个步骤的日志清晰地分离开，并实时展示。用户无需使用多个 `kubectl` 命令去手动查找 Pod 和日志，可以直接在 UI 上定位到失败步骤和错误信息，极大地简化了调试过程。

#### 2. 在多租户的 CI/CD 场景下，如何确保不同租户的流水线执行环境、资源和敏感配置是严格隔离和安全的？

Kubemate 1.30.0.0 版本通过一个**基于 Kubernetes 原生机制的多层隔离模型**来确保多租户安全：

1. **Namespace 隔离** ：所有租户的流水线资源（`PipelineRun`, `TaskRun`, `Pod` 等）都在其专属的 `Namespace` 中创建，这是最基本的隔离边界。
2. **RBAC 权限隔离** ：新版本支持 **命名空间级别的角色绑定** ，甚至 **按钮级别的权限控制** 。这意味着可以精确控制租户只能在自己的 `Namespace` 内创建和管理流水线，无法看到或影响其他租户。
3. **敏感配置隔离** ：

* **凭据管理** ：通过“凭据”功能，将敏感信息存在各租户 `Namespace` 下的 `Secret` 中，实现了安全的引用。
* **密码本加密** ：新增的平台级加密功能，为静态存储的敏感信息提供了额外的、不可逆的加密保护。

1. **资源隔离 (ResourceQuota)** ：通过为每个租户的 `Namespace` 设置 `ResourceQuota`，可以限制其 CI/CD 任务能消耗的 CPU、内存等资源，防止“嘈杂邻居”问题。
2. **网络隔离 (NetworkPolicy)** ：可以为 `Namespace` 配置网络策略，限制流水线 Pod 的网络访问，防止横向移动。

#### 3. 当 Tekton 流水线中的某个长时间运行的任务失败时，如何有效地进行断点续传或仅重试失败部分，以节省时间和资源？

Tekton 本身不直接支持“断点续传”，但可以通过巧妙的设计和平台功能来模拟：

1. **缓存是关键** ：这是最重要的策略。通过为构建依赖（如 `.m2` 目录）挂载 PVC，即使任务失败重跑，已下载的依赖也能被复用，从而跳过大量耗时步骤，实现“事实上的”续传。
2. **任务粒度化** ：将一个大的任务拆分为多个逻辑独立的 `Task`（例如：`拉取代码` -> `编译` -> `单元测试`）。如果 `单元测试` 失败，重跑时前两个已成功的任务可以利用缓存快速完成。
3. **平台辅助重试** ：虽然文档未提及，但 Kubemate 这样的平台可以提供“从失败处重试”的功能。点击后，平台可以智能地创建一个新的 `PipelineRun`，并跳过（或快速执行）那些已经成功的任务。
4. **内置重试机制** ：对于因网络抖动等临时性问题导致的失败，可以在 `Task` 中设置 `retries` 字段，让 Tekton 自动重试。

#### 4. Jenkins 作为传统的 CI/CD 工具，与云原生的 Tekton 在设计理念和运维模式上有较大差异。将两者集成时，如何解决配置管理、状态同步和用户体验不一致的问题？

根据您的新文档，这个问题的答案已经改变： **这不是一个集成问题，而是一个迁移问题** 。Kubemate 解决的是如何引导用户平滑地从 Jenkins 迁移到 Tekton。

* **配置管理** ：通过提供**构建模板**和**UI 指导**来解决。用户参照旧的 Jenkins Job，在 Kubemate 的 UI 上填写参数，由平台负责生成正确的 Tekton 配置。配置的唯一真实来源（Single Source of Truth）最终变成了存储在 Kubemate（背后是 K8s CRD）中的 Tekton 资源。
* **状态同步** ：不存在状态同步问题，因为 Jenkins 在新流程中不运行，它只是一个静态的配置参考。
* **用户体验不一致** ：通过将所有用户引导到 Kubemate **统一的管理控制台**来解决。无论是新项目还是从 Jenkins 迁移过来的项目，最终都在同一个界面中进行操作、监控和管理，提供了完全一致的用户体验。

#### 5. 对于需要 GPU 资源进行构建或测试的流水线，Tekton 是如何与 NVIDIA GPU Operator 配合，实现 GPU 资源的按需分配和调度的？

您提供的文档未涉及 GPU 的使用场景。不过，从技术上讲，在一个集成了 NVIDIA GPU Operator 的 Kubemate 平台中，实现方式如下：

1. **声明 GPU 需求** ：在“构建任务”的步骤（Step）定义中，需要为 Pod 模板添加标准的 Kubernetes GPU 资源请求，例如：

```yaml
   resources:
     limits:
       nvidia.com/gpu: "1" 
```

1. **调度与分配** ：当 Tekton 创建这个任务的 Pod 时，Kubernetes 调度器会识别到这个 GPU 请求，并自动将该 Pod 调度到一个拥有可用 GPU 资源的节点上。NVIDIA GPU Operator 确保了驱动和运行时环境都已就绪。
2. **平台封装** ：在 Kubemate 中，这可以被封装成一个特殊的 **构建模板** （例如“GPU 任务模板”）。用户只需选择该模板，填写自己的业务逻辑脚本，无需关心底层的资源请求和调度细节，从而简化 AI/ML 相关的 CI/CD 流程。
