---
layout:     post   				# 使用的布局（不需要改）
title:      AAll		# 标题 
subtitle:   AAll					#副标题
date:       2025-10-26				# 时间
author:     zhaohaiwen 				# 作者
header-img: img/post-bg-2025-01-07.jpg		#这篇文章标题背景图片
catalog: true 					# 是否归档
tags:						#标签
    - Fast
---
### GoLang

#### GPM模型

G就是goroutine，也就是协程，几KB的轻量级线程

M就是内核线程

P是逻辑处理器，对应一个存放G的本地队列，

有两种队列，一种是P绑定的本地队列，一种是全局队列

每个M都绑定一个P，P从本地队列取出G交给M运行

工作时，一个G被创建时会放入P的本地队列，如果本地队列满了就放入全局队列，如果P的本地队列空了就从全局队列获取G，如果获取不到就偷取其他P本地队列中的G，这就是工作偷取，通常偷取一半

如果一个G在M上执行时发生了系统调用阻塞，这个M会和G一起被内核阻塞。但Go调度器会让P与这个M解绑，然后去找一个新的M来继续执行P队列里剩下的G，这样就不会浪费CPU。等原来的G阻塞结束，它会被重新放回队列等待执行

#### Go垃圾回收

Go的垃圾回收是基于**三色标记法**的**并发标记清除**算法。

主要分为四步：

1、准备阶段：触发STW，开启混合写屏障

2、并发标记阶段（和程序并发执行）：使用三色标记法进行标记，如果程序修改了对象引用关系，混合写屏障就会介入，将被引用对象变为灰色，防止黑色对象指向白色对象，避免了本该存活的对象被误删

3、标记终止阶段：触发STW，当不存在灰色对象时，关闭混合写屏障

4、并发清除阶段：回收全部白色对象

三色标记：最开始所有对象都为白色

1、第一轮标记：根节点为黑色，被根节点引用的节点变为灰色

2、下一轮标记：灰色变为黑色并且被黑色节点引用的白色节点变为灰色

3、重复这一过程直到不存在灰色对象

4、回收白色对象

混合写屏障存在的意义就是，当并发标记的时候如果程序让一个黑色对象引用了白色对象就直接把白色对象变为灰色，避免白色对象被清除

**在GC开始时会把栈上所有对象直接标黑（这需要STW），并且在堆上启用屏障，当黑色对象引用白色对象时，会把白色对象变灰** 。

#### GPM Plus

**为什么需要 P 这个角色？只有 M 和 G 不行吗？**

不行，因为如果只有 M 和 G，那就退化成了传统的线程池模型，会有两个主要问题：

1. **全局锁竞争严重** ：所有 M 都需要从一个全局的 G 队列里获取任务。在高并发时，M 会激烈争抢这把全局锁，导致性能瓶颈。引入 P 之后，每个 M 优先在自己的本地队列上操作，几乎没有锁竞争，效率极高。
2. **缓存亲和性差** ：如果一个 G 在不同的 M（也就是不同的 CPU 核心）上被来回调度，它之前在某个 CPU 核心上运行时产生的缓存数据就会失效，导致 CPU 缓存命中率下降。P 的存在，让 G 倾向于在同一个 P 上被调度，从而更有可能在同一个 M 上执行，能更好地利用 CPU 缓存。

所以，P 的作用就是 **解耦 M 和 G** ，充当一个中间层，来**消除全局锁**并 **提高缓存命中率** 。

**P 的数量是由什么决定的？可以调整吗？**

P 的数量由 `runtime.GOMAXPROCS` 这个参数决定，在 Go 1.5 版本之后，它 **默认等于 CPU 的逻辑核心数** 。

它是可以调整的。我们可以通过设置环境变量 `GOMAXPROCS` 或者在代码里调用 `runtime.GOMAXPROCS()` 函数来修改它。

这个值的意义在于，它决定了 **同一时间最多有多少个 Goroutine 可以真正地并行执行** 。通常情况下，对于 CPU 密集型任务，保持默认值（等于 CPU 核心数）就是最佳选择，因为更多的 P 也不会有更多 CPU 资源。

但在 IO 密集型应用中，因为 Goroutine 会频繁因 IO 阻塞而让出 M，适当调大 P 的数量有时能提升一点性能，但通常默认值已经是很好的实践了。

**如果一个 Goroutine 执行了很长时间的计算（比如死循环），会发生什么？会阻塞其他 G 吗？**

不会一直阻塞其他 G。因为 Go 的调度器是**抢占式**的。

在 Go 1.14 版本之后，引入了 **基于信号的抢占式调度** 。当一个 Goroutine 连续运行超过一个固定的时间片（比如 10ms）时，Go 运行时会向它所在的 M 发送一个信号，强制中断这个 Goroutine 的执行，把它重新放回队列的末尾，然后 M 会去执行队列里的其他 Goroutine。

这样就保证了调度的公平性，即使有少数计算密集的 Goroutine，也不会饿死其他需要执行的 Goroutine，保证了整个程序的响应性。

* 1、M的数量最高1万个，但是不是由人为操控的
* 2、P的队列内G的数量最高256个，而P的数量由环境变量设置
* 3、创建G时首先会被分配到P的队列中，如果P的队列满了就分一半给全局队列
* 4、P如果空了会先从全局队列中获取一部分G。如果获取不到就从其他队列中获取一半G，
* 5、从全局队列中获取的比较慢，因为全局队列有锁
* 6、如果G创建了新的G‘，这个G’优先放在和G一样的PG

#### Go 垃圾回收 Plus

它的核心思想是：

1. 把内存里的对象分为**白、灰、黑**三种。白色是潜在的垃圾，灰色是待扫描对象，黑色是绝对存活的对象。
2. GC开始时，先把所有对象都看作白色。从根对象（比如全局变量、栈上的对象）出发，找到的对象标记为灰色。
3. 之后，不断地从灰色对象集合中取出对象，把它标记为黑色，并把它引用的所有白色对象标记为灰色。
4. 当没有灰色对象时，剩下的所有白色对象就是垃圾，可以被回收。

* **插入写屏障（Go 1.7及之前）** ：当一个黑色对象A要引用一个白色对象B时，写屏障会 **强制把白色对象B也变成灰色** 。这样就保证了B后续一定会被扫描，不会被漏掉。它的缺点是，GC结束时需要对栈进行重新扫描，STW时间较长。
* **混合写屏障（Go 1.8及之后）** ：它的核心规则是： **一个对象被标记为黑色后，它就不能再指向白色对象** 。为了遵守这个规则，写屏障会做两件事：
* 如果一个在栈上的对象被引用，就把它标记为灰色（防止栈扫描时漏掉）。
* 如果一个在堆上的对象被引用，就把它旧的引用标灰，新的引用也标灰。

#### GoLang怎么排查堆栈问题

在服务中集成 `pprof`工具

首先判断问题类型，是堆内存泄漏、栈溢出、还是协程泄漏

**如果是栈溢出**，根据panic直接找到对应代码进行调试，可能是边界问题

**排查堆内存泄漏**，在服务刚启动负载正常的时候采集一份基准快照，在服务运行一段时间过后内存明显增长后采集一份快照，并且使用pprof指令对比分析

* 采集基准快照：go tool pprof http://`<host>`:`<port>`/debug/pprof/heap > base.heap
* 快照对比分析：go tool pprof -base base.heap current.heap

并且使用pprof指令排查：

`pprof top` 查看内存增量最大的函数然后通过 `pprof list` 定位到源代码对应的行显示内存分配大小，看看哪个对象内存没有被释放

同时辅助火焰图和Prometheus进行排查

**排查协程泄漏**：和堆泄漏方法类似，首先pprof top找到对应函数然后pprof list列出内存分配，查看goroutine都阻塞在哪里，例如 `channel send`、`channel receive`、`select`，或者channel发送和接收没有配置对

通常堆泄漏是因为全局map和切片，协程泄漏是因为资源未关闭、死锁或阻塞

#### GoLang有哪些只执行一次的函数

sync.Once.Do()

init()

全局变量 + sync/atomic（手动实现）

### Docker

#### 讲一下DockerFile的多层结构

Docker 镜像采用 UnionFS 的多层只读层结构，每执行一次 Dockerfile 指令都会生成一个新的只读层，层 ID 用内容哈希标识。
构建时每层基于前一层缓存，改动只影响后续层，实现高效增量构建。
容器启动时，在镜像最顶层添加一个可写层，所有运行时修改都写在可写层

#### DockerFile中 COPY 和 ADD 的区别

COPY 仅支持本地文件/目录复制到容器

ADD 除了支持本地文件，还能**自动解压** tar 文件，并且接受 **远程 URL** 下载文件

#### Docker如何打包出比较小的镜像

* **选小基础镜像**
* **多阶段构建，使用上一构建阶段的产物进行构建**
* **合并 RUN 指令** **减少层数；**
* **每层末尾清理缓存**
* **用 .dockerignore** ：排除 .git、缓存、日志等；
* **避免安装不必要工具**

#### Docker镜像如何二次瘦身

可以使用DockerSlim进行瘦身，DockerSlim会通过静态和动态分析，找出真正使用的文件和依赖，生成一个全新的、只包含必要文件的镜像

### Kubernetes

#### k8s集群或服务器断网如何排查

这个分为多种情况

1、如果是集群整体链接不到外部网络，查看集群DNS解析是否存在问题：

DNS解析异常可能是DNS服务器问题，如果DNS解析正常，

2、在节点服务器上ping外部服务器和其他节点服务器，如果可以ping不通，是物理服务器问题，使用traceroute看看到哪一步断了，比如到交换机断了可能就是交换机VLAN出现了问题

如果可以ping通，去容器里尝试ping外部服务器和其他节点容器：

如果外部通，其他节点不通，CNI集群内部规则有问题，去查看CNI日志

如果外部不通，其他节点通，说明CNI出口规则有问题，去查看CNI日志

如果外部不通，其他节点不通，说明CNI有问题或者容器iptables有问题，去查看CNI日志

使用traceroute看看到哪步断了

#### 主节点宕机如何排查

先确保集群可用，再排查原因

1、主节点宕机，查看etcd、apiserver、controller manager有没有迁移到其他节点，先确保集群可用

2、如果有alertmanager告警，根据告警详细信息去排查，如果没有告警详细信息

3、查看服务器是否宕机，如果宕机，BMC重启服务器，登录主节点，如果BMC无法重启，硬件问题

4、如果没有宕机，登录主节点，

查看CPU/内存/磁盘 IO是否正常、traceroute是否能联通其他节点、如果无法联通其他节点，看在哪一步断开了，是否因为iptables规则或防火墙原因，或者交换机不通

5、如果磁盘正常、网络正常，查看kubeadm、kubelet、容器运行时是否正常，如果不正常查看日志根据日志调试

6、如果以上都正常但是节点不Ready，查看CNI容器是否正常工作，去容器内traceroute其他节点，根据日志修复CNI

查看kubeadm、kubelet、容器运行时是否正常

#### Kubernetes有哪些组件，如何工作

主节点：

apiserver、etcd、controller manger、kube-scheduler

* apiserver：所有请求入口
* etcd：存储集群状态信息
* controller manager：维持容器期望副本数
* kube-scheduler：分配pod到合适节点

工作节点：

kubelet、kube-proxy

* kube-proxy：维护节点上的网络规则
* kubelet：管理 Pod 和容器的生命周期

#### Kubernetes 中 Pod 的创建过程是什么？

* **用户提交** ：kubectl apply 提交 Pod YAML 到  **API Server** 。
* **API 验证** ：API Server 校验权限、格式，存入  **etcd** 。
* **Scheduler 调度** ：Scheduler 监控未调度 Pod，按策略（资源、亲和性）选择  **Node** ，打上 nodeName。
* **Kubelet 监听到** ：目标 Node 的 Kubelet 通过 API Server 发现新 Pod。
* **创建容器** ：Kubelet 调用  **容器运行时** （如 containerd/Docker）拉镜像、启动容器。
* **状态上报** ：Kubelet 持续上报 Pod 状态 → API Server → etcd，用户见 Running。

#### Fannel 与其他 CNI 有什么区别

Fannel：使用**VXLAN** 覆盖网络，不支持网络策略，性能差，兼容性好，基于iptables

Calico：基于BGP协议，三层路由，支持网络策略，性能好

Cilium：基于eBPF，七层路由，支持网络策略，性能最好，

网络策略可以比作pod级别的防火墙，用来实现pod之间的最小权限通信

#### 什么是pause容器？pause容器起到什么作用？

pause容器是所有pod的根容器，pod启动的时候会先启动一个pause容器，创建并持有网络命名空间，分配 Pod 的 IP，维护pod的网络、ip、端口信息。

Pod 生命周期以 pause 容器为准，业务容器挂了 pause 还在，IP 不变；pause 挂了整个 Pod 才挂。

pause 是 Pod 的“网络底座”和“生命周期锚点”。

### Linux

#### iptables配置过吗 X

#### oos Linux常见指令

**1. 文件操作**

* ls -l：列出文件 **详细列表** （权限、用户、时间）
* cd /path：**切换目录**
* pwd：显示**当前路径**
* mkdir：**创建目录**
* rm -rf： **强制递归删除** （危险！）
* cp：**复制**文件/目录
* mv：**移动或重命名**
* touch：**创建空文件或更新时间戳**

**2. 文件查看/编辑**

* cat：**一次性输出文件内容**
* less： **分页查看** （可上下翻）
* head -n 10：显示**前10行**
* tail -f： **实时跟踪日志** （神器）
* vim： **编辑文件** （:w 保存，:q 退出）
* grep "key" file： **搜索关键字** （支持 -r 递归）

**3. 权限管理**

* chmod 755 file：修改权限（ **拥有者可读写执行** ，其他人只读执行）
* chown user:group file：**更改文件所有者**
* sudo：**以管理员身份执行命令**

**4. 系统监控**

* top / htop：**实时查看进程/CPU/内存**
* ps aux：列出**所有进程详情**
* df -h：查看 **磁盘使用** （human-readable）
* du -sh *：统计**当前目录各文件大小**
* free -h：查看**内存使用**
* uptime：显示**开机时长和负载**

**5. 网络 & 进程**

* ping：测试**网络连通性**
* curl： **发送 HTTP 请求** （常用于接口测试）
* wget：**下载文件**
* netstat -tulnp / ss -tulnp：查看**监听端口和进程**
* kill -9： **强制杀进程** （PID）
* systemctl status：查看 **服务状态** （如 nginx、docker）
* nslookup：测试dns解析
* traceroute：测试连通性

### Kubemate

#### 监控模块

#### 告警模块

#### 日志模块

#### 链路追踪模块

#### 服务网格模块

#### CICD模块

#### 为什么选择现有方案，好在哪里？

#### 模块速记

[模块速记](https://hodie-aurora.github.io/2025/06/18/Kubemate-%E6%A8%A1%E5%9D%97%E9%80%9F%E8%AE%B0/)

#### 链路追踪 - Loki 实际问题 - 齐鲁银行 高基数标签问题

[高基数标签问题](https://hodie-aurora.github.io/2025/06/18/Kubemate-Loki-%E9%AB%98%E5%9F%BA%E6%95%B0%E6%A0%87%E7%AD%BE%E9%97%AE%E9%A2%98/)

#### 链路追踪 - Loki 实际问题 - ERP问题 低效LogQL查询问题

[低效LogQL查询问题](https://hodie-aurora.github.io/2025/06/18/Kubemate-Loki-%E4%BD%8E%E6%95%88LogQL%E6%9F%A5%E8%AF%A2%E9%97%AE%E9%A2%98/)

#### 链路追踪 - SkyWalking 实际问题 - 北京昆仑银行 偶发性交易结算数据不一致问题

[偶发性交易结算数据不一致问题](https://hodie-aurora.github.io/2025/06/18/Kubemate-%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA-%E5%81%B6%E5%8F%91%E6%80%A7%E4%BA%A4%E6%98%93%E7%BB%93%E7%AE%97%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/)

#### 链路追踪 - SkyWalking 实际问题 - 北京光大银行 因安全策略导致的关键业务链路中断 不推荐

[因安全策略导致的关键业务链路中断](https://hodie-aurora.github.io/2025/06/18/Kubemate-%E9%93%BE%E8%B7%AF%E8%BF%BD%E8%B8%AA-%E5%9B%A0%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5%E5%AF%BC%E8%87%B4%E7%9A%84%E5%85%B3%E9%94%AE%E4%B8%9A%E5%8A%A1%E9%93%BE%E8%B7%AF%E4%B8%AD%E6%96%AD/)

#### 链路追踪 - 为什么Jaeger耗能？为什么重启集成Jaeger之后重启时间变为了之前的1.5倍？

#### 链路追踪 - 为什么SkyWalking耗能？

#### 监控模块 - 多集群 Prometheus 怎么确保数据采集不重样

#### 监控模块 - S3存储有了解过吗

#### 最复杂的模块是哪个？（分为开发/部署）

#### 需要改进的模块是哪个？（CICD）

### Others

#### 你的技术选型都是怎样决定的？是通过开源社区还是什么？都有哪些方面的考量？

主要是目前主流成熟的技术栈，我认为技术栈不一定要花哨，适合业务并且保留拓展空间的技术栈才是最好的

#### TCP三握四挥

**TCP 三次握手：**

1. **客户端 → 服务端** ：SYN（seq=x）
2. **服务端 → 客户端** ：SYN+ACK（seq=y, ack=x+1）
3. **客户端 → 服务端** ：ACK（seq=x+1, ack=y+1）

**TCP 四次挥手：**

1. **客户端 → 服务端** ：FIN（seq=x）
2. **服务端 → 客户端** ：ACK（ack=x+1）
3. **服务端 → 客户端** ：FIN（seq=y）
4. **客户端 → 服务端** ：ACK（ack=y+1）

#### 开源社区做过哪些贡献

#### 云环境巡检

云环境巡检主要是使用K8S的定时任务触发ansible的巡检流程，会采集服务器的 CPU 内存 磁盘 负载 等信息，并且确保节点、容器、镜像仓库、git仓库等资源的可用性，以及查询备份记录、S3状态、防火墙状态等内容，如果存在偏差则根据编排好的等级规则通过Alertmanager发送不通级别告警

#### 分布式存储

我在安硕的时候行方会采购NAS服务器作为分布式存储，我们自用的会使用nfs服务器，在捷誊的话cloudstack上的存储使用的是通过cloudstack csi使用cloudstack的主存储作为分布式存储，主存储通过多个linstor 部分实现分布式存储

#### minio架构了解吗 X
